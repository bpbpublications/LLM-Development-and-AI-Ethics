{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk9KD5qXJMQZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_length=512):\n",
        "        # Set padding token if it doesn't exist\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        self.encodings = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = item['input_ids'].clone()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def finetuning_data():\n",
        "    texts = [\n",
        "        \"Question: What is machine learning? Answer: Machine learning is a branch of AI that enables systems to learn from data.\",\n",
        "        \"Question: Whar is neural networks? Answer: Neural networks are computing systems inspired by biological neural networks.\",\n",
        "        \"Question: What is deep learning? Answer: Deep learning is a subset of machine learning that uses neural networks with multiple hidden layers.\",\n",
        "        \"Question: What is computer vision? Answer: Computer vision is a field of AI that enables computers to interpret and understand the visual world.\",\n",
        "        \"Question: What is natural language processing? Answer: It is a field of AI that enables computers to understand, interpret, and utilize human language.\"\n",
        "    ]\n",
        "    return texts"
      ],
      "metadata": {
        "id": "4iXMTMPFSMtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(model_name=\"gpt2\", output_dir=\"./fine_tuned_model\"):\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "    # Set padding token for both tokenizer and model\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "    # Prepare dataset\n",
        "    texts = finetuning_data()\n",
        "    dataset = CustomDataset(texts, tokenizer)\n",
        "\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(output_dir=output_dir,num_train_epochs=3,\n",
        "        per_device_train_batch_size=4, save_steps=100, save_total_limit=2,\n",
        "        logging_steps=10, learning_rate=2e-5, weight_decay=0.01,\n",
        "        report_to=[\"none\"], logging_dir=\"./logs\")\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n",
        "\n",
        "    # Start training\n",
        "    trainer.train()\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    return output_dir"
      ],
      "metadata": {
        "id": "LCSJk6k3TdXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(prompt, model_path, max_length=30):\n",
        "    \"\"\"\n",
        "    Generate a response using the fine-tuned model.\n",
        "    \"\"\"\n",
        "    # Load the fine-tuned model and tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "    # Set padding token if it doesn't exist\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "    # Prepare input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    # Generate response\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs.input_ids, max_length=max_length,\n",
        "            num_return_sequences=1, pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id, do_sample=True, temperature=0.7)\n",
        "\n",
        "    # Decode and return response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response"
      ],
      "metadata": {
        "id": "Xq9rxNbUSMzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune and get model path of the fine-tuned the model\n",
        "model_path = fine_tune_model()\n",
        "\n",
        "# Example usage of the fine-tuned model\n",
        "prompt = \"Question: What is reinforcement learning?\"\n",
        "response = generate_response(prompt, model_path)\n",
        "print(f\"Generated response: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "UqyCpA-ySM26",
        "outputId": "9257df09-1f70-44b3-9ef8-804c5215a775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-d3404f51b0d6>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6/6 00:21, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated response: Question: What is reinforcement learning?\n",
            "\n",
            "A reinforcement learning is a process that uses information from your environment to help you learn and improve. It is\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}